{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7427525",
   "metadata": {},
   "source": [
    "# üéØ Knowledge Tracing with AKT + LLM Pipeline\n",
    "\n",
    "## Objective\n",
    "Predict whether a student will answer a question **Correctly** or **Incorrectly** by combining:\n",
    "1. **Question Context** - Text embeddings from the LLM itself\n",
    "2. **Student History Context** - Learning state embeddings from the AKT model\n",
    "\n",
    "## Pipeline Overview\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| 1. Setup | Load config, select preset (small/standard), initialize wandb |\n",
    "| 2. EDA | Load dataset, explore data distribution, understand features |\n",
    "| 3. AKT Training | Train Attentive Knowledge Tracing model, checkpoint best model |\n",
    "| 4. Embedding Extraction | Get student history embeddings from trained AKT |\n",
    "| 5. LLM Fine-tuning | Adapt LLM to understand both question text + history embeddings |\n",
    "| 6. Evaluation | Test predictions on validation samples |\n",
    "\n",
    "## Model Presets\n",
    "- **small**: TinyLlama-1.1B, minimal data, for quick testing\n",
    "- **standard**: Phi-2, balanced performance  \n",
    "- **phi3**: Phi-3 Mini, excellent quality\n",
    "- **qwen**: Qwen2-1.5B, good multilingual support\n",
    "- **llama2**: Llama-2-7B, highest quality (needs more GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Proxy settings loaded from .env file\n",
      "  HTTP Proxy: http://10.61.11.42:3128\n",
      "  HTTPS Proxy: http://10.61.11.42:3128\n",
      "‚úì Hugging Face token loaded from .env file\n",
      "‚úì Applied preset: Small (Testing)\n",
      "  Minimal configuration for quick testing and debugging\n",
      "  LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "  Embedding dim: 768 ‚Üí LLM hidden: 2048\n",
      "‚úì Applied preset: Small (Testing)\n",
      "  Minimal configuration for quick testing and debugging\n",
      "  LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "  Embedding dim: 768 ‚Üí LLM hidden: 2048\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "AVAILABLE MODEL PRESETS\n",
      "======================================================================\n",
      "\n",
      "üì¶ small ‚Üê ACTIVE\n",
      "   Name: Small (Testing)\n",
      "   Description: Minimal configuration for quick testing and debugging\n",
      "   LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "   Hidden Size: 2048\n",
      "   Data: 5 users, 100 interactions\n",
      "\n",
      "üì¶ standard\n",
      "   Name: Standard (Balanced)\n",
      "   Description: Balanced configuration for good results with reasonable resources\n",
      "   LLM: microsoft/phi-2\n",
      "   Hidden Size: 2560\n",
      "   Data: 100 users, 5000 interactions\n",
      "\n",
      "üì¶ phi3\n",
      "   Name: Phi-3 Mini\n",
      "   Description: Microsoft Phi-3 Mini - excellent performance for its size\n",
      "   LLM: microsoft/Phi-3-mini-4k-instruct\n",
      "   Hidden Size: 3072\n",
      "   Data: 200 users, 10000 interactions\n",
      "\n",
      "üì¶ qwen\n",
      "   Name: Qwen2-1.5B\n",
      "   Description: Alibaba Qwen2 - good for multilingual tasks\n",
      "   LLM: Qwen/Qwen2-1.5B\n",
      "   Hidden Size: 1536\n",
      "   Data: 200 users, 10000 interactions\n",
      "\n",
      "üì¶ llama2\n",
      "   Name: Llama-2-7B\n",
      "   Description: Meta Llama 2 - powerful but requires more resources\n",
      "   LLM: meta-llama/Llama-2-7b-hf\n",
      "   Hidden Size: 4096\n",
      "   Data: 500 users, 20000 interactions\n",
      "\n",
      "======================================================================\n",
      "Usage: Config.use_preset('preset_name')\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "üéØ ACTIVE PRESET: SMALL\n",
      "   Small (Testing) - Minimal configuration for quick testing and debugging\n",
      "\n",
      "üìä DATA:\n",
      "  Max Interactions: 100\n",
      "  Max Users: 5\n",
      "  Max Sequence Length: 50\n",
      "  Test Split: 20%\n",
      "\n",
      "üß† AKT MODEL:\n",
      "  Embedding Dim: 768\n",
      "  Attention Heads: 4\n",
      "  Transformer Layers: 2\n",
      "  Batch Size: 32\n",
      "  Epochs: 5\n",
      "  Learning Rate: 0.0001\n",
      "  Dropout: 0.15\n",
      "\n",
      "ü§ñ LLM FINE-TUNING:\n",
      "  Model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "  LLM Hidden Size: 2048\n",
      "  Soft Tokens: 4\n",
      "  Batch Size: 8\n",
      "  Epochs: 2\n",
      "  Learning Rate: 0.0002\n",
      "\n",
      "üîó EMBEDDING ADAPTER:\n",
      "  AKT ‚Üí LLM: 768 ‚Üí 2048\n",
      "  Adapter Hidden: 1408\n",
      "  Soft Tokens: 4\n",
      "\n",
      "üîß LORA:\n",
      "  Rank: 8\n",
      "  Alpha: 16\n",
      "  Dropout: 0.1\n",
      "\n",
      "‚öôÔ∏è  OPTIMIZATION:\n",
      "  GPU: ‚úì Enabled\n",
      "  Mixed Precision: ‚úì Enabled\n",
      "  Gradient Accumulation: 2 steps\n",
      "\n",
      "üìä EXPERIMENT TRACKING:\n",
      "  Wandb: ‚úì Enabled\n",
      "  Entity: letrongducanh456-viettel\n",
      "  Project: LLM-KT\n",
      "  Save Model: ‚úì Yes\n",
      "\n",
      "üìÅ OUTPUT PATHS:\n",
      "  AKT Checkpoints: checkpoints/akt/small\n",
      "  LLM Checkpoints: checkpoints/llm/small\n",
      "  Embeddings: embeddings/small/\n",
      "======================================================================\n",
      "\n",
      "‚úì All directories created\n",
      "‚úì Using device: CPU\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: SETUP - Load Configuration & Initialize Environment\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables (includes proxy settings, WandB API key, and HF token)\n",
    "load_dotenv()\n",
    "\n",
    "# Set proxy environment variables for network requests\n",
    "if os.getenv('HTTP_PROXY'):\n",
    "    os.environ['HTTP_PROXY'] = os.getenv('HTTP_PROXY')\n",
    "    os.environ['HTTPS_PROXY'] = os.getenv('HTTPS_PROXY')\n",
    "    os.environ['http_proxy'] = os.getenv('http_proxy')\n",
    "    os.environ['https_proxy'] = os.getenv('https_proxy')\n",
    "    print(\"‚úì Proxy settings loaded from .env file\")\n",
    "    print(f\"  HTTP Proxy: {os.environ['HTTP_PROXY']}\")\n",
    "    print(f\"  HTTPS Proxy: {os.environ['HTTPS_PROXY']}\")\n",
    "\n",
    "# Set Hugging Face token for model downloads\n",
    "if os.getenv('HF_TOKEN'):\n",
    "    os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "    os.environ['HUGGING_FACE_HUB_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "    print(\"‚úì Hugging Face token loaded from .env file\")\n",
    "\n",
    "# Load configuration\n",
    "from config import Config\n",
    "\n",
    "# ============================================================================\n",
    "# SELECT YOUR PRESET HERE\n",
    "# ============================================================================\n",
    "# Options: \"small\" (testing), \"standard\" (balanced), \"phi3\", \"qwen\", \"llama2\"\n",
    "\n",
    "PRESET = \"small\"  # ‚Üê Change this to switch models\n",
    "\n",
    "# Apply the preset\n",
    "Config.use_preset(PRESET)\n",
    "\n",
    "# Show available presets\n",
    "print(\"\\n\")\n",
    "Config.list_presets()\n",
    "\n",
    "# Show full configuration\n",
    "print(\"\\n\")\n",
    "Config.print_config()\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE ALL NECESSARY DIRECTORIES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CREATING DIRECTORY STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "directories_to_create = [\n",
    "    (Config.AKT_CHECKPOINT_DIR, \"AKT Model Checkpoints\"),\n",
    "    (Config.LLM_CHECKPOINT_DIR, \"LLM Model Checkpoints\"),\n",
    "    (Config.CHECKPOINT_DIR, \"General Checkpoints\"),\n",
    "    (Config.EMBEDDING_DIR, \"Student Embeddings\"),\n",
    "    (Config.OUTPUT_DIR, \"Training Outputs & Plots\"),\n",
    "    (Config.AKT_LOG_DIR, \"Training Logs\"),\n",
    "    (Config.DATA_DIR, \"Dataset Files\"),\n",
    "    ('assets', \"Visualizations & Assets\")\n",
    "]\n",
    "\n",
    "for dir_path, description in directories_to_create:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"  ‚úì {description:30} ‚Üí {dir_path}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úì All directories created successfully\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n‚úì Using device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4fb61",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset & Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section we:\n",
    "1. Load the MOOCRadar dataset (problems and student interactions)\n",
    "2. Explore data distributions (correctness, skills, users)\n",
    "3. Understand the data structure for model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0dc5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING MOOCRADAR DATASET\n",
      "======================================================================\n",
      "\n",
      "[2.0] Checking dataset files...\n",
      "‚úì Using cached file: dataset/MOOCRadar/problem.json\n",
      "‚úì Using cached file: dataset/MOOCRadar/student-problem-coarse-flattened.json\n",
      "\n",
      "[2.1] Loading problem metadata...\n",
      "‚úì Loaded 9383 problems\n",
      "\n",
      "Sample problem structure:\n",
      "  ‚Ä¢ problem_id: Pm_2046133\n",
      "  ‚Ä¢ exercise_id: Ex_1641736\n",
      "  ‚Ä¢ course_id: C_674920\n",
      "  ‚Ä¢ detail: {'problem_id': 2046133, 'title': 'Á¨¨‰∏ÄÁ´†‰Ωú‰∏ö', 'content...\n",
      "  ‚Ä¢ knowledge_type: 2\n",
      "  ‚Ä¢ cognitive_dimension: 4\n",
      "  ‚Ä¢ concepts: ['ÁªèÊµéÂèëÂ±ïÈÄªËæë', 'ÈÄªËæëÂ≠¶']\n",
      "\n",
      "[2.2] Loading student interactions...\n",
      "‚úì Loaded 898933 total interactions\n",
      "\n",
      "Sample interaction structure:\n",
      "  ‚Ä¢ log_id: 1002476_5940094\n",
      "  ‚Ä¢ problem_id: Pm_668265\n",
      "  ‚Ä¢ user_id: U_1002476\n",
      "  ‚Ä¢ is_correct: 1\n",
      "  ‚Ä¢ attempts: 1\n",
      "  ‚Ä¢ score: None\n",
      "  ‚Ä¢ submit_time: 2020-12-13 12:02:59\n",
      "  ‚Ä¢ skill_id: C_697360\n",
      "  ‚Ä¢ course_id: C_697360\n",
      "\n",
      "[2.3] Enriching interactions with problem metadata...\n",
      "‚úì Using 100 interactions (limit: 100)\n",
      "\n",
      "======================================================================\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä Dataset Overview:\n",
      "  ‚Ä¢ Total interactions: 100\n",
      "  ‚Ä¢ Unique users: 3\n",
      "  ‚Ä¢ Unique problems: 100\n",
      "  ‚Ä¢ Unique skills: 3\n",
      "\n",
      "üìà Correctness Distribution:\n",
      "  ‚Ä¢ Correct: 88 (88.0%)\n",
      "  ‚Ä¢ Incorrect: 12 (12.0%)\n",
      "\n",
      "üë§ Interactions per User:\n",
      "  ‚Ä¢ Mean: 33.3\n",
      "  ‚Ä¢ Min: 24\n",
      "  ‚Ä¢ Max: 51\n",
      "  ‚Ä¢ Median: 25.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Visualization saved to: assets/dataset_analysis.png\n",
      "\n",
      "[2.5] Grouping interactions by student...\n",
      "‚úì Found 3 users with ‚â•5 interactions\n",
      "\n",
      "[2.6] Encoding categorical variables...\n",
      "‚úì Encoded 100 unique problems\n",
      "‚úì Encoded 3 unique skills\n",
      "\n",
      "[2.7] Splitting into train/validation sets...\n",
      "‚úì Train users: 2\n",
      "‚úì Val users: 1\n",
      "\n",
      "[2.8] Preparing student sequences for AKT...\n",
      "‚úì Prepared 3 student sequences\n",
      "  ‚Ä¢ Avg sequence length: 33.3\n",
      "\n",
      "======================================================================\n",
      "DATA LOADING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: LOAD DATASET & EDA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING MOOCRADAR DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.0 Download Dataset from Google Drive (with caching)\n",
    "# -----------------------------------------------------------------------------\n",
    "def download_from_gdrive(file_id, output_path):\n",
    "    \"\"\"Download file from Google Drive if not already cached locally.\"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"‚úì Using cached file: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    print(f\"‚¨áÔ∏è  Downloading from Google Drive to {output_path}...\")\n",
    "    \n",
    "    # Create directory if needed\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Try using gdown first (more reliable)\n",
    "    try:\n",
    "        import gdown\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        gdown.download(url, output_path, quiet=False)\n",
    "        print(f\"‚úì Download complete: {output_path}\")\n",
    "        return output_path\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  gdown not installed. Installing...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([os.sys.executable, \"-m\", \"pip\", \"install\", \"gdown\", \"--quiet\"])\n",
    "        import gdown\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        gdown.download(url, output_path, quiet=False)\n",
    "        print(f\"‚úì Download complete: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading file: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"\\n[2.0] Checking dataset files...\")\n",
    "\n",
    "# Download/cache problem.json\n",
    "problem_json_path = download_from_gdrive(\n",
    "    Config.GDRIVE_FILES[\"problem.json\"],\n",
    "    Config.PROBLEM_JSON\n",
    ")\n",
    "\n",
    "# Download/cache student interactions\n",
    "student_json_path = download_from_gdrive(\n",
    "    Config.GDRIVE_FILES[\"student-problem-coarse-flattened.json\"],\n",
    "    Config.STUDENT_JSON\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.1 Load Problem Metadata (JSONL format - one JSON per line)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[2.1] Loading problem metadata...\")\n",
    "problem_info = {}\n",
    "with open(problem_json_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        problem = json.loads(line)\n",
    "        problem_info[problem['problem_id']] = problem\n",
    "\n",
    "print(f\"‚úì Loaded {len(problem_info)} problems\")\n",
    "\n",
    "# Sample problem structure\n",
    "sample_problem = list(problem_info.values())[0]\n",
    "print(f\"\\nSample problem structure:\")\n",
    "for key in sample_problem.keys():\n",
    "    value = sample_problem[key]\n",
    "    if isinstance(value, str) and len(value) > 50:\n",
    "        value = value[:50] + \"...\"\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.2 Load Student Interactions (JSON array format)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[2.2] Loading student interactions...\")\n",
    "with open(student_json_path, 'r', encoding='utf-8') as f:\n",
    "    interactions_raw = json.load(f)  # Load entire JSON array\n",
    "\n",
    "print(f\"‚úì Loaded {len(interactions_raw)} total interactions\")\n",
    "\n",
    "# Sample interaction structure\n",
    "sample_interaction = interactions_raw[0]\n",
    "print(f\"\\nSample interaction structure:\")\n",
    "for key in sample_interaction.keys():\n",
    "    print(f\"  ‚Ä¢ {key}: {sample_interaction[key]}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.3 Enrich Data & Apply Limits\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[2.3] Enriching interactions with problem metadata...\")\n",
    "data = []\n",
    "for interaction in interactions_raw[:Config.MAX_INTERACTIONS]:\n",
    "    problem_id = interaction['problem_id']\n",
    "    enriched = interaction.copy()\n",
    "    \n",
    "    if problem_id in problem_info:\n",
    "        enriched['problem_detail'] = problem_info[problem_id].get('detail', '')\n",
    "        enriched['concepts'] = problem_info[problem_id].get('concepts', [])\n",
    "        enriched['knowledge_type'] = problem_info[problem_id].get('knowledge_type', 0)\n",
    "        enriched['cognitive_dimension'] = problem_info[problem_id].get('cognitive_dimension', 0)\n",
    "    \n",
    "    data.append(enriched)\n",
    "\n",
    "print(f\"‚úì Using {len(data)} interactions (limit: {Config.MAX_INTERACTIONS})\")\n",
    "\n",
    "# Convert to DataFrame for EDA\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.4 Exploratory Data Analysis\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä Dataset Overview:\")\n",
    "print(f\"  ‚Ä¢ Total interactions: {len(df):,}\")\n",
    "print(f\"  ‚Ä¢ Unique users: {df['user_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Unique problems: {df['problem_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Unique skills: {df['skill_id'].nunique():,}\")\n",
    "\n",
    "# Correctness distribution\n",
    "correct_rate = df['is_correct'].mean()\n",
    "print(f\"\\nüìà Correctness Distribution:\")\n",
    "print(f\"  ‚Ä¢ Correct: {df['is_correct'].sum():,} ({correct_rate*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Incorrect: {(~df['is_correct'].astype(bool)).sum():,} ({(1-correct_rate)*100:.1f}%)\")\n",
    "\n",
    "# Interactions per user\n",
    "interactions_per_user = df.groupby('user_id').size()\n",
    "print(f\"\\nüë§ Interactions per User:\")\n",
    "print(f\"  ‚Ä¢ Mean: {interactions_per_user.mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Min: {interactions_per_user.min()}\")\n",
    "print(f\"  ‚Ä¢ Max: {interactions_per_user.max()}\")\n",
    "print(f\"  ‚Ä¢ Median: {interactions_per_user.median():.1f}\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Correctness Distribution\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "correct_counts = [df['is_correct'].sum(), (~df['is_correct'].astype(bool)).sum()]\n",
    "ax1.pie(correct_counts, labels=['Correct', 'Incorrect'], colors=colors, autopct='%1.1f%%',\n",
    "        startangle=90, explode=(0.05, 0))\n",
    "ax1.set_title('Correctness Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Interactions per User Distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(interactions_per_user, bins=30, color='#3498db', edgecolor='white', alpha=0.8)\n",
    "ax2.set_xlabel('Interactions per User', fontsize=10)\n",
    "ax2.set_ylabel('Count', fontsize=10)\n",
    "ax2.set_title('User Activity Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Top 15 Most Active Users\n",
    "ax3 = axes[1, 0]\n",
    "top_users = interactions_per_user.nlargest(min(15, len(interactions_per_user)))\n",
    "ax3.barh(range(len(top_users)), top_users.values, color='#9b59b6')\n",
    "ax3.set_yticks(range(len(top_users)))\n",
    "ax3.set_yticklabels([f\"User {i+1}\" for i in range(len(top_users))], fontsize=8)\n",
    "ax3.set_xlabel('Number of Interactions', fontsize=10)\n",
    "ax3.set_title(f'Top {len(top_users)} Most Active Users', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# 4. Skill Distribution (Top 15)\n",
    "ax4 = axes[1, 1]\n",
    "skill_counts = df['skill_id'].value_counts().head(15)\n",
    "ax4.bar(range(len(skill_counts)), skill_counts.values, color='#e67e22')\n",
    "ax4.set_xticks(range(len(skill_counts)))\n",
    "ax4.set_xticklabels([f\"S{i+1}\" for i in range(len(skill_counts))], fontsize=8, rotation=45)\n",
    "ax4.set_ylabel('Interaction Count', fontsize=10)\n",
    "ax4.set_title('Top 15 Most Common Skills', fontsize=12, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('MOOCRadar Dataset Overview', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "os.makedirs('assets', exist_ok=True)\n",
    "plt.savefig('assets/dataset_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Visualization saved to: assets/dataset_analysis.png\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.5 Prepare Student Sequences\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[2.5] Grouping interactions by student...\")\n",
    "user_groups = df.groupby('user_id')\n",
    "\n",
    "# Filter users with enough interactions\n",
    "min_interactions = 5\n",
    "user_groups_filtered = [(uid, group) for uid, group in user_groups if len(group) >= min_interactions]\n",
    "\n",
    "print(f\"‚úì Found {len(user_groups_filtered)} users with ‚â•{min_interactions} interactions\")\n",
    "\n",
    "# Apply MAX_USERS limit\n",
    "if len(user_groups_filtered) > Config.MAX_USERS:\n",
    "    user_groups_filtered = user_groups_filtered[:Config.MAX_USERS]\n",
    "    print(f\"‚úì Using {Config.MAX_USERS} users (limited by config)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.6 Encode Categorical Variables\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[2.6] Encoding categorical variables...\")\n",
    "\n",
    "# Collect all unique values from filtered users\n",
    "all_problems = []\n",
    "all_skills = []\n",
    "for uid, group in user_groups_filtered:\n",
    "    all_problems.extend(group['problem_id'].tolist())\n",
    "    all_skills.extend(group['skill_id'].tolist())\n",
    "\n",
    "# Create encoders\n",
    "problem_encoder = LabelEncoder()\n",
    "skill_encoder = LabelEncoder()\n",
    "\n",
    "problem_encoder.fit(list(set(all_problems)))\n",
    "skill_encoder.fit(list(set(all_skills)))\n",
    "\n",
    "# Save encoder info\n",
    "num_problems = len(problem_encoder.classes_)\n",
    "num_skills = len(skill_encoder.classes_)\n",
    "\n",
    "# Create aliases for AKT model (questions = problems, concepts = skills)\n",
    "num_questions = num_problems\n",
    "num_concepts = num_skills\n",
    "\n",
    "print(f\"‚úì Encoded {num_problems} unique problems\")\n",
    "print(f\"‚úì Encoded {num_skills} unique skills\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.7 Train/Val Split (with edge case handling)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[2.7] Splitting into train/validation sets...\")\n",
    "\n",
    "# Check if we have enough users for splitting\n",
    "if len(user_groups_filtered) < 2:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: Only {len(user_groups_filtered)} user(s) available.\")\n",
    "    print(\"   Using the same data for both train and validation (for testing purposes only)\")\n",
    "    train_user_groups = user_groups_filtered\n",
    "    val_user_groups = user_groups_filtered\n",
    "else:\n",
    "    train_user_groups, val_user_groups = train_test_split(\n",
    "        user_groups_filtered, \n",
    "        test_size=Config.TEST_SIZE, \n",
    "        random_state=Config.RANDOM_SEED\n",
    "    )\n",
    "\n",
    "print(f\"‚úì Train users: {len(train_user_groups)}\")\n",
    "print(f\"‚úì Val users: {len(val_user_groups)}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.8 Prepare Student Data for AKT Training\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[2.8] Preparing student sequences for AKT...\")\n",
    "\n",
    "students_data = []\n",
    "for uid, group in train_user_groups + val_user_groups:\n",
    "    # Sort by timestamp if available\n",
    "    if 'timestamp_TW' in group.columns:\n",
    "        group = group.sort_values('timestamp_TW')\n",
    "    \n",
    "    # Encode sequences\n",
    "    questions = problem_encoder.transform(group['problem_id'].tolist())\n",
    "    concepts = skill_encoder.transform(group['skill_id'].tolist())\n",
    "    correctness = group['is_correct'].astype(int).tolist()\n",
    "    \n",
    "    students_data.append({\n",
    "        'user_id': uid,\n",
    "        'questions': questions.tolist(),\n",
    "        'concepts': concepts.tolist(),\n",
    "        'correctness': correctness\n",
    "    })\n",
    "\n",
    "print(f\"‚úì Prepared {len(students_data)} student sequences\")\n",
    "print(f\"  ‚Ä¢ Avg sequence length: {np.mean([len(s['questions']) for s in students_data]):.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA LOADING COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c15626",
   "metadata": {},
   "source": [
    "## Step 3: Build AKT Model & Train\n",
    "\n",
    "The Attentive Knowledge Tracing (AKT) model:\n",
    "1. Captures student learning history through attention mechanisms\n",
    "2. Generates embeddings representing student knowledge state\n",
    "3. These embeddings will be used as \"history context\" for LLM fine-tuning\n",
    "\n",
    "**Architecture:**\n",
    "- Question/Concept Embeddings ‚Üí Transformer Encoder ‚Üí Knowledge State\n",
    "- Output: `EMBED_DIM`-dimensional embedding per student (matching LLM hidden size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c14c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 3: BUILD ATTENTIVE KNOWLEDGE TRACING (AKT) MODEL\n",
      "======================================================================\n",
      "‚úì AKT Model classes defined:\n",
      "  ‚Ä¢ KTDataset: Handles sequence padding and batching\n",
      "  ‚Ä¢ KTDataModule: PyTorch Lightning data module\n",
      "  ‚Ä¢ AKTLightning: Transformer-based knowledge tracing model\n",
      "\n",
      "Model Configuration (from Config):\n",
      "  ‚Ä¢ Embedding Dim: 768\n",
      "  ‚Ä¢ Attention Heads: 4\n",
      "  ‚Ä¢ Transformer Layers: 2\n",
      "  ‚Ä¢ Dropout: 0.15\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: BUILD AKT MODEL\n",
    "# ============================================================================\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 3: BUILD ATTENTIVE KNOWLEDGE TRACING (AKT) MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3.1 Dataset Class for Knowledge Tracing\n",
    "# -----------------------------------------------------------------------------\n",
    "class KTDataset(Dataset):\n",
    "    \"\"\"Dataset for Knowledge Tracing sequences\"\"\"\n",
    "    def __init__(self, students_data, max_seq_len=100):\n",
    "        self.students = students_data\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.students)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        student = self.students[idx]\n",
    "        questions = student['questions'][-self.max_seq_len:]\n",
    "        concepts = student['concepts'][-self.max_seq_len:]\n",
    "        correctness = student['correctness'][-self.max_seq_len:]\n",
    "        \n",
    "        seq_len = len(questions)\n",
    "        pad_len = self.max_seq_len - seq_len\n",
    "        \n",
    "        # Pad sequences\n",
    "        questions = questions + [0] * pad_len\n",
    "        concepts = concepts + [0] * pad_len\n",
    "        correctness = correctness + [0] * pad_len\n",
    "        mask = [1] * seq_len + [0] * pad_len\n",
    "        \n",
    "        return {\n",
    "            'questions': torch.LongTensor(questions),\n",
    "            'concepts': torch.LongTensor(concepts),\n",
    "            'correctness': torch.FloatTensor(correctness),\n",
    "            'mask': torch.FloatTensor(mask)\n",
    "        }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3.2 Data Module for PyTorch Lightning\n",
    "# -----------------------------------------------------------------------------\n",
    "class KTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, students_data, batch_size=64, max_seq_len=100, test_size=0.2):\n",
    "        super().__init__()\n",
    "        self.students_data = students_data\n",
    "        self.batch_size = batch_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.test_size = test_size\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        train_data, val_data = train_test_split(\n",
    "            self.students_data, \n",
    "            test_size=self.test_size, \n",
    "            random_state=Config.RANDOM_SEED\n",
    "        )\n",
    "        self.train_dataset = KTDataset(train_data, self.max_seq_len)\n",
    "        self.val_dataset = KTDataset(val_data, self.max_seq_len)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3.3 AKT Model with PyTorch Lightning\n",
    "# -----------------------------------------------------------------------------\n",
    "class AKTLightning(pl.LightningModule):\n",
    "    \"\"\"Attentive Knowledge Tracing model with PyTorch Lightning\"\"\"\n",
    "    \n",
    "    def __init__(self, num_questions, num_concepts, embed_dim=768, num_heads=8, \n",
    "                 num_layers=2, dropout=0.15, learning_rate=5e-5, weight_decay=1e-4,\n",
    "                 warmup_epochs=5, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "        # Embeddings\n",
    "        self.question_embed = nn.Embedding(num_questions + 1, embed_dim, padding_idx=0)\n",
    "        self.concept_embed = nn.Embedding(num_concepts + 1, embed_dim, padding_idx=0)\n",
    "        self.response_embed = nn.Embedding(3, embed_dim)  # 0: pad, 1: incorrect, 2: correct\n",
    "        self.position_embed = nn.Embedding(500, embed_dim)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, \n",
    "            dim_feedforward=embed_dim * 4, dropout=dropout,\n",
    "            activation='gelu', batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layers\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(embed_dim, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "    \n",
    "    def forward(self, questions, concepts, correctness, mask):\n",
    "        batch_size, seq_len = questions.shape\n",
    "        \n",
    "        # Create position indices\n",
    "        positions = torch.arange(seq_len, device=questions.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        q_emb = self.question_embed(questions)\n",
    "        c_emb = self.concept_embed(concepts)\n",
    "        \n",
    "        # Response embedding (shift by 1 for padding)\n",
    "        response_idx = (correctness + 1).long()  # 0->1 (incorrect), 1->2 (correct)\n",
    "        r_emb = self.response_embed(response_idx)\n",
    "        \n",
    "        # Position embedding\n",
    "        p_emb = self.position_embed(positions)\n",
    "        \n",
    "        # Combine all embeddings\n",
    "        x = q_emb + c_emb + r_emb + p_emb\n",
    "        \n",
    "        # Create attention mask for transformer\n",
    "        src_key_padding_mask = (mask == 0)\n",
    "        \n",
    "        # Create causal mask to prevent looking at future\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device), diagonal=1).bool()\n",
    "        \n",
    "        # Transformer encoding\n",
    "        x = self.transformer(x, mask=causal_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Layer norm and dropout\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output prediction\n",
    "        output = self.output_layer(x).squeeze(-1)\n",
    "        \n",
    "        return output, x  # Return both predictions and embeddings\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        questions, concepts, correctness, mask = batch['questions'], batch['concepts'], batch['correctness'], batch['mask']\n",
    "        \n",
    "        predictions, _ = self(questions, concepts, correctness, mask)\n",
    "        \n",
    "        # Shift for next-step prediction\n",
    "        pred_shifted = predictions[:, :-1]\n",
    "        target_shifted = correctness[:, 1:]\n",
    "        mask_shifted = mask[:, 1:]\n",
    "        \n",
    "        # Calculate loss with label smoothing\n",
    "        loss = self._compute_loss(pred_shifted, target_shifted, mask_shifted)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            pred_binary = (torch.sigmoid(pred_shifted) > 0.5).float()\n",
    "            correct = ((pred_binary == target_shifted) * mask_shifted).sum()\n",
    "            total = mask_shifted.sum()\n",
    "            acc = correct / (total + 1e-8)\n",
    "        \n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        questions, concepts, correctness, mask = batch['questions'], batch['concepts'], batch['correctness'], batch['mask']\n",
    "        \n",
    "        predictions, _ = self(questions, concepts, correctness, mask)\n",
    "        \n",
    "        pred_shifted = predictions[:, :-1]\n",
    "        target_shifted = correctness[:, 1:]\n",
    "        mask_shifted = mask[:, 1:]\n",
    "        \n",
    "        loss = self._compute_loss(pred_shifted, target_shifted, mask_shifted)\n",
    "        \n",
    "        pred_binary = (torch.sigmoid(pred_shifted) > 0.5).float()\n",
    "        correct = ((pred_binary == target_shifted) * mask_shifted).sum()\n",
    "        total = mask_shifted.sum()\n",
    "        acc = correct / (total + 1e-8)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def _compute_loss(self, predictions, targets, mask):\n",
    "        # Binary cross entropy with label smoothing\n",
    "        smooth_targets = targets * (1 - self.label_smoothing) + 0.5 * self.label_smoothing\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            predictions, smooth_targets, reduction='none'\n",
    "        )\n",
    "        masked_loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n",
    "        return masked_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=self.warmup_epochs, T_mult=2\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def get_embeddings(self, dataloader):\n",
    "        \"\"\"Extract student knowledge state embeddings\"\"\"\n",
    "        self.eval()\n",
    "        embeddings = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                questions = batch['questions'].to(self.device)\n",
    "                concepts = batch['concepts'].to(self.device)\n",
    "                correctness = batch['correctness'].to(self.device)\n",
    "                mask = batch['mask'].to(self.device)\n",
    "                \n",
    "                _, hidden = self(questions, concepts, correctness, mask)\n",
    "                \n",
    "                # Get last valid position embedding for each student\n",
    "                for i in range(hidden.size(0)):\n",
    "                    valid_len = int(mask[i].sum().item())\n",
    "                    if valid_len > 0:\n",
    "                        student_emb = hidden[i, valid_len - 1, :].cpu().numpy()\n",
    "                    else:\n",
    "                        student_emb = hidden[i, 0, :].cpu().numpy()\n",
    "                    embeddings.append(student_emb)\n",
    "        \n",
    "        return np.array(embeddings)\n",
    "\n",
    "print(\"‚úì AKT Model classes defined:\")\n",
    "print(f\"  ‚Ä¢ KTDataset: Handles sequence padding and batching\")\n",
    "print(f\"  ‚Ä¢ KTDataModule: PyTorch Lightning data module\")\n",
    "print(f\"  ‚Ä¢ AKTLightning: Transformer-based knowledge tracing model\")\n",
    "print(f\"\\nModel Configuration (from Config):\")\n",
    "print(f\"  ‚Ä¢ Embedding Dim: {Config.EMBED_DIM}\")\n",
    "print(f\"  ‚Ä¢ Attention Heads: {Config.NUM_HEADS}\")\n",
    "print(f\"  ‚Ä¢ Transformer Layers: {Config.NUM_LAYERS}\")\n",
    "print(f\"  ‚Ä¢ Dropout: {Config.AKT_DROPOUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1acb33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING AKT MODEL\n",
      "======================================================================\n",
      "\n",
      "[3.4.1] Setting up data module...\n",
      "‚úì Train: 2 students\n",
      "‚úì Val: 1 students\n",
      "\n",
      "[3.4.2] Initializing AKT model...\n",
      "‚úì Model initialized with 14,644,993 trainable parameters\n",
      "\n",
      "[3.4.3] Setting up training callbacks...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>trainer/global_step</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_acc</td><td>0.91304</td></tr><tr><td>val_loss</td><td>0.57224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AKT-small</strong> at: <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/qsxobunz' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/qsxobunz</a><br> View project at: <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260204_152300-qsxobunz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\wandb\\run-20260204_153653-zrnrugd3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/zrnrugd3' target=\"_blank\">AKT-small</a></strong> to <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/zrnrugd3' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/zrnrugd3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Wandb initialized: AKT-small\n",
      "  ‚Üí View at: https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/zrnrugd3\n",
      "\n",
      "[3.4.4] Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type               | Params | Mode  | FLOPs\n",
      "----------------------------------------------------------------------\n",
      "0 | question_embed | Embedding          | 77.6 K | train | 0    \n",
      "1 | concept_embed  | Embedding          | 3.1 K  | train | 0    \n",
      "2 | response_embed | Embedding          | 2.3 K  | train | 0    \n",
      "3 | position_embed | Embedding          | 384 K  | train | 0    \n",
      "4 | transformer    | TransformerEncoder | 14.2 M | train | 0    \n",
      "5 | layer_norm     | LayerNorm          | 1.5 K  | train | 0    \n",
      "6 | dropout        | Dropout            | 0      | train | 0    \n",
      "7 | output_layer   | Linear             | 769    | train | 0    \n",
      "----------------------------------------------------------------------\n",
      "14.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 M    Total params\n",
      "58.580    Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.42it/s, v_num=ugd3, train_loss=0.513, train_acc=0.890, val_loss=0.473, val_acc=0.913]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.41it/s, v_num=ugd3, train_loss=0.513, train_acc=0.890, val_loss=0.473, val_acc=0.913]\n",
      "üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è üèãÔ∏è \n",
      "\n",
      "‚úì Training completed!\n",
      "‚úì Best checkpoint: C:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\checkpoints\\akt\\small\\akt-epoch=00-val_acc=0.9130-v1.ckpt\n",
      "‚úì Best validation accuracy: 0.9130\n",
      "\n",
      "[3.4.5] Loading best model for embedding extraction...\n",
      "‚úì Best model loaded\n",
      "\n",
      "[3.5] Plotting training curves...\n",
      "Available columns: ['epoch', 'step', 'val_acc', 'val_loss']\n",
      "‚ö†Ô∏è Could not find expected metric columns in CSV. Skipping plot.\n",
      "Available columns: ['epoch', 'step', 'val_acc', 'val_loss']\n",
      "\n",
      "======================================================================\n",
      "‚úì AKT MODEL TRAINING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3.4: TRAIN AKT MODEL\n",
    "# ============================================================================\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING AKT MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize data module\n",
    "print(\"\\n[3.4.1] Setting up data module...\")\n",
    "data_module = KTDataModule(\n",
    "    students_data, \n",
    "    batch_size=Config.AKT_BATCH_SIZE, \n",
    "    max_seq_len=Config.MAX_SEQ_LEN,\n",
    "    test_size=Config.TEST_SIZE\n",
    ")\n",
    "data_module.setup()\n",
    "print(f\"‚úì Train: {len(data_module.train_dataset)} students\")\n",
    "print(f\"‚úì Val: {len(data_module.val_dataset)} students\")\n",
    "\n",
    "# Initialize model\n",
    "print(\"\\n[3.4.2] Initializing AKT model...\")\n",
    "model = AKTLightning(\n",
    "    num_questions=num_questions,\n",
    "    num_concepts=num_concepts,\n",
    "    embed_dim=Config.EMBED_DIM,\n",
    "    num_heads=Config.NUM_HEADS,\n",
    "    num_layers=Config.NUM_LAYERS,\n",
    "    dropout=Config.AKT_DROPOUT,\n",
    "    learning_rate=Config.AKT_LR,\n",
    "    weight_decay=Config.AKT_WEIGHT_DECAY,\n",
    "    warmup_epochs=Config.AKT_WARMUP_EPOCHS,\n",
    "    label_smoothing=Config.AKT_LABEL_SMOOTHING\n",
    ")\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"‚úì Model initialized with {trainable_params:,} trainable parameters\")\n",
    "\n",
    "# Setup callbacks\n",
    "print(\"\\n[3.4.3] Setting up training callbacks...\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath=Config.AKT_CHECKPOINT_DIR,\n",
    "    filename='akt-{epoch:02d}-{val_acc:.4f}',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=Config.AKT_EARLY_STOP_PATIENCE,\n",
    "    mode='max',\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "# Setup loggers\n",
    "csv_logger = CSVLogger(Config.AKT_LOG_DIR, name='akt_training')\n",
    "loggers = [csv_logger]\n",
    "\n",
    "# Initialize wandb if enabled\n",
    "if Config.USE_WANDB:\n",
    "    wandb_run = wandb.init(\n",
    "        entity=Config.WANDB_ENTITY,\n",
    "        project=Config.WANDB_PROJECT,\n",
    "        name=f\"AKT-{Config.ACTIVE_PRESET}\",\n",
    "        config={\n",
    "            \"preset\": Config.ACTIVE_PRESET,\n",
    "            \"model\": \"AKT\",\n",
    "            \"embed_dim\": Config.EMBED_DIM,\n",
    "            \"num_heads\": Config.NUM_HEADS,\n",
    "            \"num_layers\": Config.NUM_LAYERS,\n",
    "            \"batch_size\": Config.AKT_BATCH_SIZE,\n",
    "            \"learning_rate\": Config.AKT_LR,\n",
    "            \"epochs\": Config.AKT_EPOCHS,\n",
    "            \"num_students\": len(students_data),\n",
    "            \"num_questions\": num_questions,\n",
    "            \"num_concepts\": num_concepts,\n",
    "        }\n",
    "    )\n",
    "    wandb_logger = WandbLogger(experiment=wandb_run)\n",
    "    loggers.append(wandb_logger)\n",
    "    print(f\"‚úì Wandb initialized: {wandb_run.name}\")\n",
    "    print(f\"  ‚Üí View at: {wandb_run.get_url()}\")\n",
    "\n",
    "# Initialize trainer\n",
    "print(\"\\n[3.4.4] Starting training...\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=Config.AKT_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    logger=loggers,\n",
    "    accelerator='auto' if Config.USE_GPU else 'cpu',\n",
    "    devices=1,\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    "    accumulate_grad_batches=Config.GRADIENT_ACCUMULATION,\n",
    "    precision='16-mixed' if Config.MIXED_PRECISION else 32,\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm='norm'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"üèãÔ∏è \" * 35)\n",
    "trainer.fit(model, data_module)\n",
    "print(\"üèãÔ∏è \" * 35)\n",
    "\n",
    "print(f\"\\n‚úì Training completed!\")\n",
    "print(f\"‚úì Best checkpoint: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"‚úì Best validation accuracy: {checkpoint_callback.best_model_score:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "print(\"\\n[3.4.5] Loading best model for embedding extraction...\")\n",
    "best_model = AKTLightning.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    num_questions=num_questions,\n",
    "    num_concepts=num_concepts\n",
    ")\n",
    "print(\"‚úì Best model loaded\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3.5 Plot Training Curves\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[3.5] Plotting training curves...\")\n",
    "\n",
    "# Read metrics from CSV logger\n",
    "metrics_path = f'{Config.AKT_LOG_DIR}/akt_training/version_{csv_logger.version}/metrics.csv'\n",
    "metrics_df = pd.read_csv(metrics_path)\n",
    "\n",
    "# Check what columns are available\n",
    "print(f\"Available columns: {list(metrics_df.columns)}\")\n",
    "\n",
    "# PyTorch Lightning logs metrics with 'train/' and 'val/' prefixes or without\n",
    "# Let's handle both cases\n",
    "train_loss_col = None\n",
    "train_acc_col = None\n",
    "val_loss_col = None\n",
    "val_acc_col = None\n",
    "\n",
    "for col in metrics_df.columns:\n",
    "    if 'train' in col.lower() and 'loss' in col.lower():\n",
    "        train_loss_col = col\n",
    "    elif 'train' in col.lower() and 'acc' in col.lower():\n",
    "        train_acc_col = col\n",
    "    elif 'val' in col.lower() and 'loss' in col.lower():\n",
    "        val_loss_col = col\n",
    "    elif 'val' in col.lower() and 'acc' in col.lower():\n",
    "        val_acc_col = col\n",
    "\n",
    "if train_loss_col and val_loss_col:\n",
    "    # Prepare data\n",
    "    train_metrics = metrics_df[metrics_df[train_loss_col].notna()][['epoch', train_loss_col, train_acc_col]]\n",
    "    train_metrics.columns = ['epoch', 'train_loss', 'train_acc']\n",
    "    \n",
    "    val_metrics = metrics_df[metrics_df[val_loss_col].notna()][['epoch', val_loss_col, val_acc_col]]\n",
    "    val_metrics.columns = ['epoch', 'val_loss', 'val_acc']\n",
    "    \n",
    "    metrics_combined = pd.merge(\n",
    "        train_metrics.groupby('epoch').mean().reset_index(),\n",
    "        val_metrics.groupby('epoch').mean().reset_index(),\n",
    "        on='epoch'\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(metrics_combined['epoch'], metrics_combined['train_loss'], 'b-o', label='Train', markersize=6)\n",
    "    axes[0].plot(metrics_combined['epoch'], metrics_combined['val_loss'], 'r-s', label='Val', markersize=6)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[0].set_ylabel('Loss', fontsize=11)\n",
    "    axes[0].set_title('AKT Training - Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(metrics_combined['epoch'], metrics_combined['train_acc'], 'b-o', label='Train', markersize=6)\n",
    "    axes[1].plot(metrics_combined['epoch'], metrics_combined['val_acc'], 'r-s', label='Val', markersize=6)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[1].set_ylabel('Accuracy', fontsize=11)\n",
    "    axes[1].set_title('AKT Training - Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('akt_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úì Training curves saved as 'akt_training_curves.png'\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not find expected metric columns in CSV. Skipping plot.\")\n",
    "    print(f\"Available columns: {list(metrics_df.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úì AKT MODEL TRAINING COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a567822",
   "metadata": {},
   "source": [
    "## Step 4: Extract Embeddings & Prepare for LLM Fine-tuning\n",
    "\n",
    "Now we extract two types of embeddings for the LLM:\n",
    "\n",
    "1. **Student History Embeddings** (from AKT)\n",
    "   - Captures the student's learning history and knowledge state\n",
    "   - Dimension: `EMBED_DIM` (configured to match or adapt to LLM)\n",
    "\n",
    "2. **Question Context Embeddings** (from LLM)\n",
    "   - Text embeddings of the question content\n",
    "   - Extracted using the LLM's own tokenizer/encoder\n",
    "   - Dimension: `LLM_HIDDEN_SIZE`\n",
    "\n",
    "**Prediction Task:** Given history + question context ‚Üí Correct/Incorrect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca6fba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 4: EXTRACT EMBEDDINGS FOR LLM FINE-TUNING\n",
      "======================================================================\n",
      "\n",
      "[4.1] Extracting student history embeddings from AKT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Train embeddings shape: (2, 768)\n",
      "‚úì Val embeddings shape: (1, 768)\n",
      "‚úì Embedding dimension: 768\n",
      "\n",
      "‚úì Embeddings saved to:\n",
      "  ‚Ä¢ embeddings/small/student_embeddings_train.npy\n",
      "  ‚Ä¢ embeddings/small/student_embeddings_val.npy\n",
      "\n",
      "[4.2] Designing embedding adapter...\n",
      "\n",
      "Embedding Adapter Configuration:\n",
      "  ‚Ä¢ AKT Embedding Dim: 768\n",
      "  ‚Ä¢ LLM Hidden Size: 2048\n",
      "  ‚Ä¢ Adapter Hidden Dim: 1408\n",
      "  ‚Ä¢ Num Soft Tokens: 4\n",
      "\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ                    EMBEDDING FLOW ARCHITECTURE                       ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ                                                                       ‚îÇ\n",
      "‚îÇ   STUDENT HISTORY CONTEXT (from AKT):                                ‚îÇ\n",
      "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
      "‚îÇ   ‚îÇ  AKT Embeddings ‚îÇ (768-dim)                             ‚îÇ\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
      "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
      "‚îÇ            ‚ñº                                                          ‚îÇ\n",
      "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
      "‚îÇ   ‚îÇ History Adapter ‚îÇ MLP: 768 ‚Üí 2048           ‚îÇ\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
      "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
      "‚îÇ            ‚ñº                                                          ‚îÇ\n",
      "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
      "‚îÇ   ‚îÇ  Soft Tokens    ‚îÇ (4 tokens √ó 2048-dim)        ‚îÇ\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
      "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
      "‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                                ‚îÇ\n",
      "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
      "‚îÇ   QUESTION CONTEXT (from LLM tokenizer):                             ‚îÇ\n",
      "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
      "‚îÇ   ‚îÇ  Text Tokens    ‚îÇ (question content, concepts, etc.)             ‚îÇ\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
      "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
      "‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                                ‚îÇ\n",
      "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
      "‚îÇ            ‚ñº                                                          ‚îÇ\n",
      "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ\n",
      "‚îÇ   ‚îÇ  [SOFT_TOKENS] + [TEXT_TOKENS]          ‚îÇ                        ‚îÇ\n",
      "‚îÇ   ‚îÇ              ‚Üì                          ‚îÇ                        ‚îÇ\n",
      "‚îÇ   ‚îÇ     LLM (TinyLlama-1.1B-Chat-v1.0)                           ‚îÇ\n",
      "‚îÇ   ‚îÇ         (with LoRA)                     ‚îÇ                        ‚îÇ\n",
      "‚îÇ   ‚îÇ              ‚Üì                          ‚îÇ                        ‚îÇ\n",
      "‚îÇ   ‚îÇ        Classifier                       ‚îÇ                        ‚îÇ\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ\n",
      "‚îÇ                       ‚Üì                                              ‚îÇ\n",
      "‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ\n",
      "‚îÇ              ‚îÇ Correct (1)   ‚îÇ                                       ‚îÇ\n",
      "‚îÇ              ‚îÇ Incorrect (0) ‚îÇ                                       ‚îÇ\n",
      "‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ\n",
      "‚îÇ                                                                       ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "======================================================================\n",
      "‚úì EMBEDDING EXTRACTION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: EXTRACT EMBEDDINGS & PREPARE FOR LLM FINE-TUNING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 4: EXTRACT EMBEDDINGS FOR LLM FINE-TUNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4.1 Extract Student History Embeddings from AKT\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[4.1] Extracting student history embeddings from AKT...\")\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "# Extract embeddings\n",
    "train_embeddings = best_model.get_embeddings(data_module.train_dataloader())\n",
    "val_embeddings = best_model.get_embeddings(data_module.val_dataloader())\n",
    "all_embeddings = np.vstack([train_embeddings, val_embeddings])\n",
    "\n",
    "print(f\"‚úì Train embeddings shape: {train_embeddings.shape}\")\n",
    "print(f\"‚úì Val embeddings shape: {val_embeddings.shape}\")\n",
    "print(f\"‚úì Embedding dimension: {train_embeddings.shape[1]}\")\n",
    "\n",
    "# Create embeddings directory if needed\n",
    "os.makedirs(os.path.dirname(Config.TRAIN_EMBEDDINGS), exist_ok=True)\n",
    "\n",
    "# Save embeddings\n",
    "np.save(Config.TRAIN_EMBEDDINGS, train_embeddings)\n",
    "np.save(Config.VAL_EMBEDDINGS, val_embeddings)\n",
    "np.save(Config.ALL_EMBEDDINGS, all_embeddings)\n",
    "\n",
    "print(f\"\\n‚úì Embeddings saved to:\")\n",
    "print(f\"  ‚Ä¢ {Config.TRAIN_EMBEDDINGS}\")\n",
    "print(f\"  ‚Ä¢ {Config.VAL_EMBEDDINGS}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4.2 Embedding Adapter Architecture\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[4.2] Designing embedding adapter...\")\n",
    "\n",
    "adapter_config = Config.get_embedding_adapter_config()\n",
    "print(f\"\\nEmbedding Adapter Configuration:\")\n",
    "print(f\"  ‚Ä¢ AKT Embedding Dim: {adapter_config['akt_embed_dim']}\")\n",
    "print(f\"  ‚Ä¢ LLM Hidden Size: {adapter_config['llm_hidden_size']}\")\n",
    "print(f\"  ‚Ä¢ Adapter Hidden Dim: {adapter_config['adapter_hidden_dim']}\")\n",
    "print(f\"  ‚Ä¢ Num Soft Tokens: {adapter_config['num_soft_tokens']}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    EMBEDDING FLOW ARCHITECTURE                       ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                       ‚îÇ\n",
    "‚îÇ   STUDENT HISTORY CONTEXT (from AKT):                                ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
    "‚îÇ   ‚îÇ  AKT Embeddings ‚îÇ ({adapter_config['akt_embed_dim']}-dim)                             ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
    "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
    "‚îÇ            ‚ñº                                                          ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
    "‚îÇ   ‚îÇ History Adapter ‚îÇ MLP: {adapter_config['akt_embed_dim']} ‚Üí {adapter_config['llm_hidden_size']}           ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
    "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
    "‚îÇ            ‚ñº                                                          ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
    "‚îÇ   ‚îÇ  Soft Tokens    ‚îÇ ({adapter_config['num_soft_tokens']} tokens √ó {adapter_config['llm_hidden_size']}-dim)        ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
    "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
    "‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                                ‚îÇ\n",
    "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
    "‚îÇ   QUESTION CONTEXT (from LLM tokenizer):                             ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ\n",
    "‚îÇ   ‚îÇ  Text Tokens    ‚îÇ (question content, concepts, etc.)             ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ\n",
    "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
    "‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                                ‚îÇ\n",
    "‚îÇ            ‚îÇ                                                          ‚îÇ\n",
    "‚îÇ            ‚ñº                                                          ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ\n",
    "‚îÇ   ‚îÇ  [SOFT_TOKENS] + [TEXT_TOKENS]          ‚îÇ                        ‚îÇ\n",
    "‚îÇ   ‚îÇ              ‚Üì                          ‚îÇ                        ‚îÇ\n",
    "‚îÇ   ‚îÇ     LLM ({Config.LLM_MODEL_NAME.split('/')[-1]})                           ‚îÇ\n",
    "‚îÇ   ‚îÇ         (with LoRA)                     ‚îÇ                        ‚îÇ\n",
    "‚îÇ   ‚îÇ              ‚Üì                          ‚îÇ                        ‚îÇ\n",
    "‚îÇ   ‚îÇ        Classifier                       ‚îÇ                        ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ\n",
    "‚îÇ                       ‚Üì                                              ‚îÇ\n",
    "‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ\n",
    "‚îÇ              ‚îÇ Correct (1)   ‚îÇ                                       ‚îÇ\n",
    "‚îÇ              ‚îÇ Incorrect (0) ‚îÇ                                       ‚îÇ\n",
    "‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ\n",
    "‚îÇ                                                                       ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úì EMBEDDING EXTRACTION COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec953033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 5: DEFINE LLM MODEL WITH EMBEDDING ADAPTER\n",
      "======================================================================\n",
      "\n",
      "‚úì KnowledgeTracingLLM class defined\n",
      "‚úì KTLlamaDataset class defined\n",
      "\n",
      "Using LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "Embedding: 768 ‚Üí 2048\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: LLM MODEL DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 5: DEFINE LLM MODEL WITH EMBEDDING ADAPTER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class KnowledgeTracingLLM(nn.Module):\n",
    "    \"\"\"\n",
    "    LLM model with AKT embedding injection for knowledge tracing.\n",
    "    \n",
    "    Supports multiple LLMs (TinyLlama, Phi-2, Phi-3, Qwen, Llama-2).\n",
    "    The AKT embedding is projected as a soft prompt prefix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, akt_embed_dim, llm_hidden_size, \n",
    "                 num_soft_tokens=8, lora_r=16, lora_alpha=32, lora_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.akt_embed_dim = akt_embed_dim\n",
    "        self.llm_hidden_size = llm_hidden_size\n",
    "        self.num_soft_tokens = num_soft_tokens\n",
    "        \n",
    "        print(f\"\\n[5.1] Loading LLM: {model_name}\")\n",
    "        print(f\"  ‚Üí AKT Embedding Dim: {akt_embed_dim}\")\n",
    "        print(f\"  ‚Üí LLM Hidden Size: {llm_hidden_size}\")\n",
    "        print(f\"  ‚Üí Soft Tokens: {num_soft_tokens}\")\n",
    "        \n",
    "        # Quantization config for memory efficiency\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Load config first to handle Phi-3 rope_scaling issue\n",
    "        print(\"  ‚Üí Loading model configuration...\")\n",
    "        model_config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "        \n",
    "        # Fix Phi-3 rope_scaling issue\n",
    "        if \"phi-3\" in model_name.lower() or \"phi3\" in model_name.lower():\n",
    "            print(\"  ‚Üí Detected Phi-3 model, applying rope_scaling fix...\")\n",
    "            if hasattr(model_config, 'rope_scaling') and model_config.rope_scaling is not None:\n",
    "                if isinstance(model_config.rope_scaling, dict) and 'type' not in model_config.rope_scaling:\n",
    "                    # Add default 'type' if missing\n",
    "                    model_config.rope_scaling['type'] = 'default'\n",
    "                    print(\"  ‚Üí Fixed rope_scaling configuration\")\n",
    "            # Use eager attention to avoid rope scaling issues\n",
    "            model_config._attn_implementation = \"eager\"\n",
    "            print(\"  ‚Üí Using eager attention implementation\")\n",
    "        \n",
    "        # Load model with quantization\n",
    "        print(\"  ‚Üí Loading with 4-bit quantization...\")\n",
    "        self.llm = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            config=model_config,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            trust_remote_code=True,\n",
    "            attn_implementation=\"eager\" if \"phi-3\" in model_name.lower() or \"phi3\" in model_name.lower() else None\n",
    "        )\n",
    "        \n",
    "        # Prepare for training\n",
    "        self.llm = prepare_model_for_kbit_training(self.llm)\n",
    "        \n",
    "        # LoRA configuration for efficient fine-tuning\n",
    "        lora_config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=Config.LORA_TARGET_MODULES,\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "        self.llm = get_peft_model(self.llm, lora_config)\n",
    "        \n",
    "        print(f\"  ‚Üí LoRA applied: r={lora_r}, alpha={lora_alpha}\")\n",
    "        \n",
    "        # AKT Embedding Adapter: Projects AKT embedding to soft prompt tokens\n",
    "        adapter_hidden = (akt_embed_dim + llm_hidden_size) // 2\n",
    "        \n",
    "        self.embedding_adapter = nn.Sequential(\n",
    "            nn.Linear(akt_embed_dim, adapter_hidden),\n",
    "            nn.LayerNorm(adapter_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(adapter_hidden, num_soft_tokens * llm_hidden_size),\n",
    "        )\n",
    "        \n",
    "        # Initialize adapter with small weights\n",
    "        for module in self.embedding_adapter:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, std=0.02)\n",
    "                nn.init.zeros_(module.bias)\n",
    "        \n",
    "        # Binary classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(llm_hidden_size, llm_hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(llm_hidden_size // 2, 2)  # Correct / Incorrect\n",
    "        )\n",
    "        \n",
    "        print(\"  ‚Üí Embedding adapter initialized\")\n",
    "        print(\"  ‚Üí Classifier head initialized\")\n",
    "        \n",
    "    def get_soft_prompt(self, akt_embedding):\n",
    "        \"\"\"Convert AKT embedding to soft prompt tokens.\"\"\"\n",
    "        batch_size = akt_embedding.size(0)\n",
    "        soft_prompt = self.embedding_adapter(akt_embedding)\n",
    "        soft_prompt = soft_prompt.view(batch_size, self.num_soft_tokens, self.llm_hidden_size)\n",
    "        return soft_prompt\n",
    "    \n",
    "    def forward(self, akt_embedding, input_ids, attention_mask=None):\n",
    "        \"\"\"Forward pass with AKT embedding injection.\"\"\"\n",
    "        batch_size = akt_embedding.size(0)\n",
    "        \n",
    "        # Get soft prompt from AKT embedding\n",
    "        soft_prompt = self.get_soft_prompt(akt_embedding)\n",
    "        \n",
    "        # Get text embeddings from LLM\n",
    "        text_embeds = self.llm.get_input_embeddings()(input_ids)\n",
    "        \n",
    "        # Concatenate: [SOFT_PROMPT_TOKENS] + [TEXT_TOKENS]\n",
    "        combined_embeds = torch.cat([soft_prompt, text_embeds], dim=1)\n",
    "        \n",
    "        # Update attention mask\n",
    "        if attention_mask is not None:\n",
    "            soft_prompt_mask = torch.ones(batch_size, self.num_soft_tokens, device=attention_mask.device)\n",
    "            combined_attention_mask = torch.cat([soft_prompt_mask, attention_mask], dim=1)\n",
    "        else:\n",
    "            combined_attention_mask = None\n",
    "        \n",
    "        # Forward through LLM\n",
    "        outputs = self.llm(\n",
    "            inputs_embeds=combined_embeds,\n",
    "            attention_mask=combined_attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        # Get last hidden state at the last position\n",
    "        last_hidden_state = outputs.hidden_states[-1][:, -1, :]\n",
    "        \n",
    "        # Classify as Correct/Incorrect\n",
    "        logits = self.classifier(last_hidden_state)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def predict(self, akt_embedding, question_id, concept_name, difficulty=\"medium\", content=\"\"):\n",
    "        \"\"\"Make a prediction for a single student-question interaction.\"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        if akt_embedding.dim() == 1:\n",
    "            akt_embedding = akt_embedding.unsqueeze(0)\n",
    "        \n",
    "        prompt = f\"\"\"<s>[INST] Predict if student answers correctly.\n",
    "Question: {question_id} | Concept: {concept_name} | Difficulty: {difficulty}\n",
    "Content: {content[:100]}\n",
    "Answer: [/INST]\"\"\"\n",
    "        \n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "        input_ids = inputs[\"input_ids\"].to(akt_embedding.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(akt_embedding.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = self(akt_embedding, input_ids, attention_mask)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            pred_class = torch.argmax(probs, dim=-1).item()\n",
    "            confidence = probs[0, pred_class].item()\n",
    "        \n",
    "        prediction = \"Correct\" if pred_class == 1 else \"Incorrect\"\n",
    "        return prediction, confidence\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Dataset for LLM Fine-tuning\n",
    "# -----------------------------------------------------------------------------\n",
    "class KTLlamaDataset(Dataset):\n",
    "    \"\"\"Dataset for fine-tuning LLM with AKT embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, akt_embeddings, students_metadata, tokenizer, max_length=512):\n",
    "        self.akt_embeddings = torch.FloatTensor(akt_embeddings)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Flatten to individual predictions\n",
    "        self.samples = []\n",
    "        for student_idx, student_meta in enumerate(students_metadata):\n",
    "            interactions = student_meta['interactions']\n",
    "            for t in range(1, len(interactions)):\n",
    "                interaction = interactions[t]\n",
    "                \n",
    "                problem_detail = interaction.get('problem_detail', '')\n",
    "                concepts = interaction.get('concepts', [])\n",
    "                \n",
    "                content = str(problem_detail)[:200] if problem_detail else ''\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'student_idx': student_idx,\n",
    "                    'problem_id': interaction['problem_id'],\n",
    "                    'content': content,\n",
    "                    'concepts': concepts,\n",
    "                    'correctness': interaction['is_correct']\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        akt_embedding = self.akt_embeddings[sample['student_idx']]\n",
    "        \n",
    "        concepts_str = \", \".join(sample['concepts'][:3]) if sample['concepts'] else \"General\"\n",
    "        content = sample['content'][:100] if sample['content'] else \"N/A\"\n",
    "        \n",
    "        prompt = f\"\"\"<s>[INST] Predict if student answers correctly.\n",
    "Problem: {sample['problem_id']} | Concepts: {concepts_str}\n",
    "Content: {content}\n",
    "Answer: [/INST]\"\"\"\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'akt_embedding': akt_embedding,\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'label': torch.LongTensor([1 if sample['correctness'] else 0]).squeeze(0),\n",
    "            'problem_id': sample['problem_id']\n",
    "        }\n",
    "\n",
    "print(\"\\n‚úì KnowledgeTracingLLM class defined\")\n",
    "print(\"‚úì KTLlamaDataset class defined\")\n",
    "print(f\"\\nUsing LLM: {Config.LLM_MODEL_NAME}\")\n",
    "print(f\"Embedding: {Config.EMBED_DIM} ‚Üí {Config.LLM_HIDDEN_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a175b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 5.2: FINE-TUNE LLM WITH AKT EMBEDDINGS\n",
      "======================================================================\n",
      "\n",
      "[5.2.1] Initializing LLM Model...\n",
      "\n",
      "[5.1] Loading LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "  ‚Üí AKT Embedding Dim: 768\n",
      "  ‚Üí LLM Hidden Size: 2048\n",
      "  ‚Üí Soft Tokens: 4\n",
      "  ‚Üí Loading with 4-bit quantization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [05:40<00:00,  1.69s/it, Materializing param=model.norm.weight]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí LoRA applied: r=8, alpha=16\n",
      "  ‚Üí Embedding adapter initialized\n",
      "  ‚Üí Classifier head initialized\n",
      "\n",
      "[5.2.2] Preparing Datasets...\n",
      "  ‚Üí Train samples: 73\n",
      "  ‚Üí Val samples: 24\n",
      "\n",
      "[5.2.3] Initializing WandB...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>trainer/global_step</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_acc</td><td>0.91304</td></tr><tr><td>val_loss</td><td>0.47266</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AKT-small</strong> at: <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/zrnrugd3' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/zrnrugd3</a><br> View project at: <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260204_153653-zrnrugd3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\wandb\\run-20260204_154311-hi0c6r9g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/hi0c6r9g' target=\"_blank\">llm-small-20260204_1543</a></strong> to <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/hi0c6r9g' target=\"_blank\">https://wandb.ai/letrongducanh456-viettel/LLM-KT/runs/hi0c6r9g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5.2.4] Starting LLM Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 [Train]:   0%|          | 0/10 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5.2: LLM FINE-TUNING WITH WANDB\n",
    "# ============================================================================\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 5.2: FINE-TUNE LLM WITH AKT EMBEDDINGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize the KnowledgeTracingLLM model\n",
    "print(\"\\n[5.2.1] Initializing LLM Model...\")\n",
    "kt_llm = KnowledgeTracingLLM(\n",
    "    model_name=Config.LLM_MODEL_NAME,\n",
    "    akt_embed_dim=Config.EMBED_DIM,\n",
    "    llm_hidden_size=Config.LLM_HIDDEN_SIZE,\n",
    "    num_soft_tokens=Config.NUM_SOFT_TOKENS,\n",
    "    lora_r=Config.LORA_R,\n",
    "    lora_alpha=Config.LORA_ALPHA,\n",
    "    lora_dropout=Config.LORA_DROPOUT\n",
    ")\n",
    "\n",
    "# Prepare training and validation data\n",
    "print(\"\\n[5.2.2] Preparing Datasets...\")\n",
    "\n",
    "# Create simple metadata from user groups\n",
    "train_metadata = []\n",
    "for uid, group in train_user_groups:\n",
    "    interactions = [\n",
    "        {\n",
    "            'problem_id': row['problem_id'],\n",
    "            'is_correct': row['is_correct'],\n",
    "            'problem_detail': row.get('problem_detail', ''),\n",
    "            'concepts': row.get('concepts', []) if isinstance(row.get('concepts'), list) else []\n",
    "        }\n",
    "        for _, row in group.iterrows()\n",
    "    ]\n",
    "    train_metadata.append({'user_id': uid, 'interactions': interactions})\n",
    "\n",
    "val_metadata = []\n",
    "for uid, group in val_user_groups:\n",
    "    interactions = [\n",
    "        {\n",
    "            'problem_id': row['problem_id'],\n",
    "            'is_correct': row['is_correct'],\n",
    "            'problem_detail': row.get('problem_detail', ''),\n",
    "            'concepts': row.get('concepts', []) if isinstance(row.get('concepts'), list) else []\n",
    "        }\n",
    "        for _, row in group.iterrows()\n",
    "    ]\n",
    "    val_metadata.append({'user_id': uid, 'interactions': interactions})\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = KTLlamaDataset(train_embeddings, train_metadata, kt_llm.tokenizer, Config.MAX_PROMPT_LENGTH)\n",
    "val_dataset = KTLlamaDataset(val_embeddings, val_metadata, kt_llm.tokenizer, Config.MAX_PROMPT_LENGTH)\n",
    "\n",
    "print(f\"  ‚Üí Train samples: {len(train_dataset):,}\")\n",
    "print(f\"  ‚Üí Val samples: {len(val_dataset):,}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.LLM_BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.LLM_BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize WandB for LLM training\n",
    "print(\"\\n[5.2.3] Initializing WandB...\")\n",
    "wandb.init(\n",
    "    project=\"LLM-KT\",\n",
    "    entity=\"letrongducanh456-viettel\",\n",
    "    name=f\"llm-{Config.current_preset}-{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "    config={\n",
    "        \"preset\": Config.current_preset,\n",
    "        \"llm_model\": Config.LLM_MODEL_NAME,\n",
    "        \"llm_hidden_size\": Config.LLM_HIDDEN_SIZE,\n",
    "        \"akt_embed_dim\": Config.EMBED_DIM,\n",
    "        \"num_soft_tokens\": Config.NUM_SOFT_TOKENS,\n",
    "        \"lora_r\": Config.LORA_R,\n",
    "        \"lora_alpha\": Config.LORA_ALPHA,\n",
    "        \"llm_batch_size\": Config.LLM_BATCH_SIZE,\n",
    "        \"llm_epochs\": Config.LLM_EPOCHS,\n",
    "        \"llm_lr\": Config.LLM_LR,\n",
    "        \"train_samples\": len(train_dataset),\n",
    "        \"val_samples\": len(val_dataset)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Optimizer - Train adapter + classifier + LoRA weights\n",
    "llm_optimizer = optim.AdamW([\n",
    "    {'params': kt_llm.embedding_adapter.parameters(), 'lr': Config.LLM_LR},\n",
    "    {'params': kt_llm.classifier.parameters(), 'lr': Config.LLM_LR},\n",
    "    {'params': kt_llm.llm.parameters(), 'lr': Config.LLM_LR * 0.1}  # Lower LR for LoRA\n",
    "], weight_decay=0.01)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "print(\"\\n[5.2.4] Starting LLM Fine-tuning...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "kt_llm = kt_llm.to(device)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "for epoch in range(Config.LLM_EPOCHS):\n",
    "    # Training phase\n",
    "    kt_llm.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.LLM_EPOCHS} [Train]\")\n",
    "    for batch in progress_bar:\n",
    "        akt_emb = batch['akt_embedding'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        llm_optimizer.zero_grad()\n",
    "        logits = kt_llm(akt_emb, input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(kt_llm.parameters(), 1.0)\n",
    "        llm_optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        epoch_correct += (preds == labels).sum().item()\n",
    "        epoch_total += labels.size(0)\n",
    "        \n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{epoch_correct/epoch_total:.3f}\")\n",
    "    \n",
    "    train_loss = epoch_loss / len(train_loader)\n",
    "    train_acc = epoch_correct / epoch_total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validation phase\n",
    "    kt_llm.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{Config.LLM_EPOCHS} [Val]\"):\n",
    "            akt_emb = batch['akt_embedding'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            logits = kt_llm(akt_emb, input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"\\n  Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "    \n",
    "    # Log to WandB\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc\n",
    "    })\n",
    "    \n",
    "    # Checkpoint if best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # Ensure checkpoint directory exists\n",
    "        os.makedirs(Config.CHECKPOINT_DIR, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(Config.CHECKPOINT_DIR, \"llm_best.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': kt_llm.state_dict(),\n",
    "            'optimizer_state_dict': llm_optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'config': Config.current_preset\n",
    "        }, checkpoint_path)\n",
    "        wandb.save(checkpoint_path)\n",
    "        print(f\"  ‚úì New best model saved! Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "print(f\"LLM Fine-tuning Complete! Best Val Accuracy: {best_val_acc:.4f}\")print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b627e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined: train_kt_llama()\n",
      "======================================================================\n",
      "\n",
      "Training Configuration:\n",
      "  - Optimizer: AdamW with weight decay\n",
      "  - Scheduler: CosineAnnealingLR\n",
      "  - Loss: CrossEntropyLoss\n",
      "  - Gradient Clipping: max_norm=1.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5.3: PLOT LLM TRAINING CURVES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 5.3: VISUALIZE LLM TRAINING PROGRESS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(epochs_range, train_losses, 'b-', linewidth=2, label='Train Loss', marker='o', markersize=4)\n",
    "axes[0].plot(epochs_range, val_losses, 'r-', linewidth=2, label='Val Loss', marker='s', markersize=4)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('LLM Fine-tuning: Loss Curves', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(epochs_range)\n",
    "\n",
    "# Accuracy curves\n",
    "axes[1].plot(epochs_range, train_accs, 'b-', linewidth=2, label='Train Accuracy', marker='o', markersize=4)\n",
    "axes[1].plot(epochs_range, val_accs, 'r-', linewidth=2, label='Val Accuracy', marker='s', markersize=4)\n",
    "axes[1].axhline(y=best_val_acc, color='g', linestyle='--', alpha=0.7, label=f'Best Val Acc: {best_val_acc:.3f}')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('LLM Fine-tuning: Accuracy Curves', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(epochs_range)\n",
    "\n",
    "plt.suptitle(f'LLM Training Summary ({Config.current_preset} preset)', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
    "plt.savefig(os.path.join(Config.OUTPUT_DIR, 'llm_training_curves.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Training curves saved to: {os.path.join(Config.OUTPUT_DIR, 'llm_training_curves.png')}\")\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  ‚Üí Final Train Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"  ‚Üí Final Val Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"  ‚Üí Final Train Acc: {train_accs[-1]:.4f}\")\n",
    "print(f\"  ‚Üí Final Val Acc: {val_accs[-1]:.4f}\")\n",
    "print(f\"  ‚Üí Best Val Acc: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49535482",
   "metadata": {},
   "source": [
    "## üìä Step 6: Evaluation & Testing\n",
    "\n",
    "**Objective:** Load the fine-tuned model and test with sample predictions.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the best checkpoint\n",
    "2. Test on sample student-question pairs\n",
    "3. Compute evaluation metrics (Accuracy, AUC, F1)\n",
    "4. Visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4605c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING TINYLLAMA-1.1B FINE-TUNING FOR KNOWLEDGE TRACING\n",
      "======================================================================\n",
      "\n",
      "[1/6] Loading AKT embeddings and enriched metadata...\n",
      "‚úì Loaded embeddings - Train: (8, 4096), Val: (2, 4096)\n",
      "‚úì Metadata split - Train: 8 students, Val: 2 students\n",
      "\n",
      "[2/6] Initializing TinyLlama-1.1B model...\n",
      "  ‚Üí Loading model with 4-bit quantization...\n",
      "  ‚Üí This may take a few minutes on first run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond' thrown while requesting HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'[WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond' thrown while requesting HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'[WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond' thrown while requesting HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'[WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond' thrown while requesting HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'[WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond' thrown while requesting HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'[WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond' thrown while requesting HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json\n",
      "'[WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond' thrown while requesting HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  ‚Üí Loading model with 4-bit quantization...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  ‚Üí This may take a few minutes on first run...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m kt_llama = \u001b[43mKnowledgeTracingLlama\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTinyLlama/TinyLlama-1.1B-Chat-v1.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_soft_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì Model initialized successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ‚Üí Trainable parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mkt_llama.parameters()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mp.requires_grad)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mKnowledgeTracingLlama.__init__\u001b[39m\u001b[34m(self, model_name, embed_dim, num_soft_tokens)\u001b[39m\n\u001b[32m     19\u001b[39m bnb_config = BitsAndBytesConfig(\n\u001b[32m     20\u001b[39m     load_in_4bit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     21\u001b[39m     bnb_4bit_use_double_quant=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     22\u001b[39m     bnb_4bit_quant_type=\u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     bnb_4bit_compute_dtype=torch.float16\n\u001b[32m     24\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Load Llama2-7B tokenizer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28mself\u001b[39m.tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mself\u001b[39m.tokenizer.pad_token = \u001b[38;5;28mself\u001b[39m.tokenizer.eos_token\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Load Llama2-7B model with quantization\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:621\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    617\u001b[39m         config = AutoConfig.from_pretrained(\n\u001b[32m    618\u001b[39m             pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs\n\u001b[32m    619\u001b[39m         )\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m         config = \u001b[43mPreTrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m config_model_type = config.model_type\n\u001b[32m    625\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:531\u001b[39m, in \u001b[36mPreTrainedConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[39m\n\u001b[32m    528\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mlocal_files_only\u001b[39m\u001b[33m\"\u001b[39m] = local_files_only\n\u001b[32m    529\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mrevision\u001b[39m\u001b[33m\"\u001b[39m] = revision\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.base_config_key \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.base_config_key \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[32m    533\u001b[39m     config_dict = config_dict[\u001b[38;5;28mcls\u001b[39m.base_config_key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:569\u001b[39m, in \u001b[36mPreTrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:624\u001b[39m, in \u001b[36mPreTrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    623\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    638\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:276\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    222\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m | os.PathLike,\n\u001b[32m    223\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    224\u001b[39m     **kwargs,\n\u001b[32m    225\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    226\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    228\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:419\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    418\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    433\u001b[39m         snapshot_download(\n\u001b[32m    434\u001b[39m             path_or_repo_id,\n\u001b[32m    435\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    444\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         validate_repo_id(arg_value)\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1024\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1003\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m   1004\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m   1005\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m         dry_run=dry_run,\n\u001b[32m   1022\u001b[39m     )\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1157\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, _DEFAULT_RETRY_ON_EXCEPTIONS) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1152\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError)\n\u001b[32m   1153\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code \u001b[38;5;129;01min\u001b[39;00m _DEFAULT_RETRY_ON_STATUS_CODES\n\u001b[32m   1154\u001b[39m     ):\n\u001b[32m   1155\u001b[39m         logger.info(\u001b[33m\"\u001b[39m\u001b[33mNo local file found. Retrying..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1156\u001b[39m         (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = (\n\u001b[32m-> \u001b[39m\u001b[32m1157\u001b[39m             \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ETAG_RETRY_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m         )\n\u001b[32m   1173\u001b[39m \u001b[38;5;66;03m# If still error, raise\u001b[39;00m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1691\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder, retry_on_errors)\u001b[39m\n\u001b[32m   1689\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1690\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1691\u001b[39m         metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[43m            \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1697\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m RemoteEntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1700\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1701\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         validate_repo_id(arg_value)\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1614\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, timeout, library_name, library_version, user_agent, headers, endpoint, retry_on_errors)\u001b[39m\n\u001b[32m   1611\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1613\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m response = \u001b[43m_httpx_follow_relative_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_errors\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1617\u001b[39m hf_raise_for_status(response)\n\u001b[32m   1619\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:302\u001b[39m, in \u001b[36m_httpx_follow_relative_redirects\u001b[39m\u001b[34m(method, url, retry_on_errors, **httpx_kwargs)\u001b[39m\n\u001b[32m    297\u001b[39m no_retry_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = (\n\u001b[32m    298\u001b[39m     {} \u001b[38;5;28;01mif\u001b[39;00m retry_on_errors \u001b[38;5;28;01melse\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mretry_on_exceptions\u001b[39m\u001b[33m\"\u001b[39m: (), \u001b[33m\"\u001b[39m\u001b[33mretry_on_status_codes\u001b[39m\u001b[33m\"\u001b[39m: ()}\n\u001b[32m    299\u001b[39m )\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhttpx_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mno_retry_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m     hf_raise_for_status(response)\n\u001b[32m    311\u001b[39m     \u001b[38;5;66;03m# Check if response is a relative redirect\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:506\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_backoff\u001b[39m(\n\u001b[32m    442\u001b[39m     method: HTTP_METHOD_T,\n\u001b[32m    443\u001b[39m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m     **kwargs,\n\u001b[32m    451\u001b[39m ) -> httpx.Response:\n\u001b[32m    452\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrapper around httpx to retry calls on an endpoint, with exponential backoff.\u001b[39;00m\n\u001b[32m    453\u001b[39m \n\u001b[32m    454\u001b[39m \u001b[33;03m    Endpoint call is retried on exceptions (ex: connection timeout, proxy error,...)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    504\u001b[39m \u001b[33;03m    > issue on [Github](https://github.com/huggingface/huggingface_hub).\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_http_backoff_base\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:414\u001b[39m, in \u001b[36m_http_backoff_base\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, stream, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_retry(response):\n\u001b[32m    416\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpx\\_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_lock:\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m         ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m         http2_negotiated = (\n\u001b[32m     82\u001b[39m             ssl_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     83\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m ssl_object.selected_alpn_protocol() == \u001b[33m\"\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    116\u001b[39m     kwargs = {\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhost\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._origin.host.decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mport\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._origin.port,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msocket_options\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._socket_options,\n\u001b[32m    122\u001b[39m     }\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m         trace.return_value = stream\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DUCANH\\OneDrive - VNU-HCMUS\\Desktop\\AI tutor\\LLM-KT\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:208\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     sock = \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m socket_options:\n\u001b[32m    214\u001b[39m         sock.setsockopt(*option)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:844\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m error \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    843\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m         \u001b[43mexceptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# raise only the last error\u001b[39;00m\n\u001b[32m    845\u001b[39m     exceptions.append(exc)\n\u001b[32m    846\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: EVALUATION & TESTING\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 6: EVALUATE FINE-TUNED LLM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load best checkpoint\n",
    "print(\"\\n[6.1] Loading Best Model Checkpoint...\")\n",
    "checkpoint_path = os.path.join(Config.CHECKPOINT_DIR, \"llm_best.pt\")\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    kt_llm.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"  ‚Üí Loaded checkpoint from epoch {checkpoint['epoch']+1}\")\n",
    "    print(f\"  ‚Üí Val Accuracy: {checkpoint['val_acc']:.4f}\")\n",
    "else:\n",
    "    print(\"  ‚ö† No checkpoint found, using current model state\")\n",
    "\n",
    "kt_llm.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "kt_llm = kt_llm.to(device)\n",
    "\n",
    "# Full evaluation on validation set\n",
    "print(\"\\n[6.2] Running Full Evaluation...\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        akt_emb = batch['akt_embedding'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        logits = kt_llm(akt_emb, input_ids, attention_mask)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        preds = torch.argmax(probs, dim=-1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "try:\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "except:\n",
    "    auc = 0.0\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  AUC:       {auc:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n[6.3] Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Incorrect', 'Correct']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n[6.4] Confusion Matrix:\")\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Incorrect', 'Correct'], \n",
    "            yticklabels=['Incorrect', 'Correct'], ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('Actual', fontsize=12)\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14)\n",
    "\n",
    "# Probability Distribution\n",
    "axes[1].hist(all_probs[all_labels == 0], bins=30, alpha=0.6, label='Incorrect', color='red')\n",
    "axes[1].hist(all_probs[all_labels == 1], bins=30, alpha=0.6, label='Correct', color='green')\n",
    "axes[1].set_xlabel('Predicted Probability (Correct)', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Prediction Probability Distribution', fontsize=14)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
    "plt.savefig(os.path.join(Config.OUTPUT_DIR, 'evaluation_results.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Test with Sample Predictions\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n[6.5] Sample Predictions:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Get some samples from validation set\n",
    "num_samples = 5\n",
    "sample_indices = np.random.choice(len(val_dataset), num_samples, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    sample = val_dataset[idx]\n",
    "    akt_emb = sample['akt_embedding'].unsqueeze(0).to(device)\n",
    "    input_ids = sample['input_ids'].unsqueeze(0).to(device)\n",
    "    attention_mask = sample['attention_mask'].unsqueeze(0).to(device)\n",
    "    true_label = sample['label'].item()\n",
    "    problem_id = sample['problem_id']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = kt_llm(akt_emb, input_ids, attention_mask)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        pred = torch.argmax(probs, dim=-1).item()\n",
    "        confidence = probs[0, pred].item()\n",
    "    \n",
    "    true_str = \"Correct\" if true_label == 1 else \"Incorrect\"\n",
    "    pred_str = \"Correct\" if pred == 1 else \"Incorrect\"\n",
    "    match = \"‚úì\" if pred == true_label else \"‚úó\"\n",
    "    \n",
    "    print(f\"\\nSample {i+1}: Problem {problem_id}\")\n",
    "    print(f\"  True: {true_str:10} | Predicted: {pred_str:10} | Confidence: {confidence:.3f} | {match}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Evaluation Complete!\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SUMMARY & NEXT STEPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üéâ LLM-KT PIPELINE COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                        EXPERIMENT SUMMARY                             ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë  Preset Used:     {Config.current_preset:49} ‚ïë\n",
    "‚ïë  LLM Model:       {Config.LLM_MODEL_NAME[:49]:49} ‚ïë\n",
    "‚ïë  AKT Embed Dim:   {str(Config.EMBED_DIM):49} ‚ïë\n",
    "‚ïë  LLM Hidden Size: {str(Config.LLM_HIDDEN_SIZE):49} ‚ïë\n",
    "‚ïë  Best Val Acc:    {str(round(best_val_acc, 4)):49} ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")\n",
    "\n",
    "# Verify saved files\n",
    "print(\"üìÅ Saved Checkpoints & Outputs:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "saved_files = [\n",
    "    (\"AKT Best Model\", os.path.join(Config.AKT_CHECKPOINT_DIR, \"*.ckpt\")),\n",
    "    (\"LLM Best Model\", os.path.join(Config.CHECKPOINT_DIR, \"llm_best.pt\")),\n",
    "    (\"Train Embeddings\", Config.TRAIN_EMBEDDINGS),\n",
    "    (\"Val Embeddings\", Config.VAL_EMBEDDINGS),\n",
    "    (\"Training Curves\", os.path.join(Config.OUTPUT_DIR, \"llm_training_curves.png\")),\n",
    "    (\"Evaluation Plot\", os.path.join(Config.OUTPUT_DIR, \"evaluation_results.png\")),\n",
    "    (\"Dataset Analysis\", \"assets/dataset_analysis.png\"),\n",
    "    (\"AKT Training Curves\", \"akt_training_curves.png\")\n",
    "]\n",
    "\n",
    "import glob\n",
    "\n",
    "for name, path in saved_files:\n",
    "    if '*' in path:\n",
    "        # Handle glob patterns\n",
    "        matches = glob.glob(path)\n",
    "        if matches:\n",
    "            print(f\"  ‚úì {name:25} ‚Üí {matches[0]}\")\n",
    "        else:\n",
    "            print(f\"  ‚úó {name:25} ‚Üí Not found\")\n",
    "    elif os.path.exists(path):\n",
    "        file_size = os.path.getsize(path)\n",
    "        size_mb = file_size / (1024 * 1024)\n",
    "        print(f\"  ‚úì {name:25} ‚Üí {path} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {name:25} ‚Üí {path} (not found)\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Directory summary\n",
    "print(\"\\nüìÇ Directory Structure:\")\n",
    "print(\"=\" * 70)\n",
    "directories = [\n",
    "    Config.AKT_CHECKPOINT_DIR,\n",
    "    Config.LLM_CHECKPOINT_DIR,\n",
    "    Config.CHECKPOINT_DIR,\n",
    "    Config.EMBEDDING_DIR,\n",
    "    Config.OUTPUT_DIR,\n",
    "    Config.AKT_LOG_DIR,\n",
    "    \"assets\"\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    if os.path.exists(directory):\n",
    "        file_count = len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
    "        print(f\"  üìÅ {directory:30} ‚Üí {file_count} files\")\n",
    "    else:\n",
    "        print(f\"  üìÅ {directory:30} ‚Üí (not created)\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüîÑ To try a different LLM preset:\")\n",
    "print(\"  1. Change PRESET variable in Cell 2\")\n",
    "print(\"  2. Re-run from Cell 2 onwards\")\n",
    "print(\"  3. Available presets: small, standard, phi3, qwen, llama2\")\n",
    "\n",
    "print(\"\\nüìù Quick Reference:\")\n",
    "Config.list_presets()\n",
    "\n",
    "print(\"\\n‚úÖ All done! Check WandB for training logs and comparisons.\")\n",
    "print(f\"   WandB Project: {Config.WANDB_PROJECT}\")\n",
    "print(f\"   WandB Entity: {Config.WANDB_ENTITY}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
